{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_generator.ipynb","provenance":[{"file_id":"1A4XfLISNo3YUtYtHFvg--OMLWGUSDmzk","timestamp":1650198855077},{"file_id":"1BhMQfHbzXm09CJlxGfjkihAXwSBZ371e","timestamp":1648734536579},{"file_id":"1zFdm8ow4ViRQdfHcoliNFYh9RAtTfA-f","timestamp":1647853601229}],"collapsed_sections":[],"mount_file_id":"1A4XfLISNo3YUtYtHFvg--OMLWGUSDmzk","authorship_tag":"ABX9TyPHMEfUhnf+/rasEorTQJDU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## image augumentation\n"],"metadata":{"id":"-BQNV0zn4046"}},{"cell_type":"code","source":["# #image agumentation 생성\n","\n","# import cv2\n","# import numpy as np\n","# from PIL import Image\n","# import os, glob, numpy as np\n","# from sklearn.model_selection import train_test_split\n","# from numpy import expand_dims\n","# from keras.preprocessing.image import load_img\n","# from keras.preprocessing.image import img_to_array\n","# from keras.preprocessing.image import ImageDataGenerator\n","# from matplotlib import pyplot as plt\n","\n","# caltech_dir = \"/content/drive/MyDrive/hairloss_image/boundingbox\"\n","# categories = [\"m0\", \"m1\", \"m2\",]\n","# nb_classes = len(categories)\n","\n","# for idx, cat in enumerate(categories):\n","    \n","#     #one-hot 돌리기.\n","#     label = [0 for i in range(nb_classes)]\n","#     label[idx] = 1\n","#     image_dir = caltech_dir + \"/\" + cat\n","#     files = glob.glob(image_dir+\"/*.PNG\") # 확장자 주의\n","#     #files = glob.glob(image_dir+\"/*.jpg\") # 확장자 주의\n","#     print(cat, \" 파일 길이 : \", len(files))\n","#     for i, f in enumerate(files):\n","#         #Open a simple image\n","#         img = load_img(f)\n","#         data = img_to_array(img)\n","\n","#         samples = expand_dims(data, 0)\n","\n","#         # create image data augumentation generator\n","        \n","#         datagen = ImageDataGenerator(                         # 파라미터 조정\n","#                           #rescale = 1/255,   \n","#                           zoom_range=[0.8, 1.0],\n","#                           brightness_range=[0.5, 1.0],\n","#                           rotation_range=20,\n","#                           shear_range = 0.2,\n","#                           horizontal_flip=True,\n","#                           #vertical_flip=True,\n","#                           #height_shift_range=0,\n","#                           #width_shift_range=0\n","#                           fill_mode = 'nearest'\n","#                          )\n","\n","#         # prepare iterator\n","\n","#         it = datagen.flow(samples, batch_size=1)\n","\n","#         # generate samples and plot\n","\n","#         fig = plt.figure(figsize=(20,20))\n","\n","#         for k in range(10):\n","#           # define subplot\n","#           #plt.subplot(4, 3, 1 + i)\n","#           # generate batch of images\n","#           batch = it.next()\n","#           # convert to unsigned integers for viewing\n","#           image = batch[0].astype('uint8')\n","#           # plot raw pixel data\n","#           #plt.imshow(image)\n","\n","#           if cat==\"m0\":ㄱ\n","#             plt.imsave('/content/drive/MyDrive/hairloss_image/boundingbox/agumentation/m0/'+str(i)+\"_\"+str(k)+\"_\"+cat+\"_agumentation.jpg\", image)\n","            \n","#           if cat==\"m1\":\n","#             plt.imsave('/content/drive/MyDrive/hairloss_image/boundingbox/agumentation/m1/'+str(i)+\"_\"+str(k)+\"_\"+cat+\"_agumentation.jpg\", image)\n","            \n","#           if cat==\"m2\":\n","#             plt.imsave('/content/drive/MyDrive/hairloss_image/boundingbox/agumentation/m2/'+str(i)+\"_\"+str(k)+\"_\"+cat+\"_agumentation.jpg\", image)\n","           \n","\n","\n"],"metadata":{"id":"DoizOkaVByMd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from numpy import expand_dims\n","# from keras.preprocessing.image import load_img\n","# from keras.preprocessing.image import img_to_array\n","# from keras.preprocessing.image import ImageDataGenerator\n","# from matplotlib import pyplot as plt\n","\n","# img = load_img(\"/content/drive/MyDrive/hairloss_image/boundingbox/m0/1.PNG\")\n","# data = img_to_array(img)\n","\n","# # expand dimension to one sample\n","\n","# samples = expand_dims(data, 0)\n","\n","# # create image data augumentation generator\n","\n","# datagen = ImageDataGenerator(\n","#                           #rescale = 1/255,   \n","#                           zoom_range=[0.8, 1.0],\n","#                           brightness_range=[0.5, 1.0],\n","#                           rotation_range=10,\n","#                           shear_range = 0.2,\n","#                           horizontal_flip=True,\n","#                           #vertical_flip=True,\n","#                           #height_shift_range=0,\n","#                           #width_shift_range=0\n","#                           fill_mode = 'nearest'\n","#                          )\n","\n","# # prepare iterator\n","\n","# it = datagen.flow(samples, batch_size=1)\n","\n","# # generate samples and plot\n","\n","# fig = plt.figure(figsize=(20,20))\n","\n","# for i in range(12):\n","#   # define subplot\n","#   plt.subplot(4, 3, 1 + i)\n","#   # generate batch of images\n","#   batch = it.next()\n","#   # convert to unsigned integers for viewing\n","#   image = batch[0].astype('uint8')\n","#   #print(image.shape)\n","#   #print(type(image))\n","#   # plot raw pixel data\n","#   plt.imshow(image)\n","#   #plt.imsave('/content/drive/MyDrive/test.jpg', image)\n","# plt.show()"],"metadata":{"id":"VJ3zFq2A5go5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## remove_background"],"metadata":{"id":"3Xj_9S2YiWZC"}},{"cell_type":"code","source":["# Requires \"requests\" to be installed (see python-requests.org)\n","\n","# 이미지 누끼따기 크레딧 부족으로 사용 안함\n","\n","# import requests\n","# from PIL import Image\n","# import os, glob, numpy as np\n","\n","\n","# caltech_dir = \"/content/drive/MyDrive/hairloss_image\"\n","# categories = [\"m0\", \"m1\", \"m2\",]\n","# nb_classes = len(categories)\n","\n","\n","# for idx, cat in enumerate(categories):\n","    \n","#     #one-hot 돌리기.\n","#     label = [0 for i in range(nb_classes)]\n","#     label[idx] = 1\n","\n","#     image_dir = caltech_dir + \"/\" + cat\n","#     file_link = glob.glob(image_dir+\"/*.jpg\")\n","\n","#     for i, f in enumerate(file_link):\n","#         response = requests.post(\n","#         'https://api.remove.bg/v1.0/removebg',\n","#         files={'image_file': open(f, 'rb')},\n","#         data={'size': 'auto'},\n","#         headers={'X-Api-Key': 'wfSUUdFqqtnwhZedjgmJe1z3'},)\n","#         if response.status_code == requests.codes.ok:\n","#           with open('/content/drive/MyDrive/hairloss_image/remove/'+cat+\"_\"+str(i)+'.jpg', 'wb') as out:\n","#                 out.write(response.content)\n","#         else:\n","#             print(\"Error:\", response.status_code, response.text)\n","\n","    \n"],"metadata":{"id":"XcuMAtLsVYs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pip install rembg==2.0.10"],"metadata":{"id":"0hxKzvo3iSpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pip install rembg[gpu]"],"metadata":{"id":"sTgnwOrniTxE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#input_path = '/content/drive/MyDrive/hairloss_image/m0/838735341_rHOQLxs5_eb840212ea33eff37f08ee8fb2fe5ce951bf98ae.png'\n","#output_path = '/content/drive/MyDrive/hairloss_image/m0/removebg_test.png'\n","\n","\n","#input = Image.open(input_path)\n","#output = remove(input)\n","#output.save(output_path)"],"metadata":{"id":"ADLO4iwWkmw3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## skin segmentation\n"],"metadata":{"id":"bhvP9ba-ikj5"}},{"cell_type":"code","source":["# #skin detect 전처리 이미지 파일 생성 코드\n","\n","# import cv2\n","# import numpy as np\n","# from PIL import Image\n","# import os, glob, numpy as np\n","# from sklearn.model_selection import train_test_split\n","\n","# caltech_dir = \"/content/drive/MyDrive/hairloss_image/boundingbox\"\n","# categories = [\"m0\", \"m1\", \"m2\",]\n","# nb_classes = len(categories)\n","\n","# for idx, cat in enumerate(categories):\n","    \n","#     #one-hot 돌리기.\n","#     label = [0 for i in range(nb_classes)]\n","#     label[idx] = 1\n","#     image_dir = caltech_dir + \"/\" + cat\n","#     files = glob.glob(image_dir+\"/*.PNG\") # 확장자 주의\n","#     #files = glob.glob(image_dir+\"/*.jpg\") # 확장자 주의\n","#     print(cat, \" 파일 길이 : \", len(files))\n","#     for i, f in enumerate(files):\n","#         #Open a simple image\n","#         img=cv2.imread(f)\n","\n","#         #converting from gbr to hsv color space\n","#         img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","#         #skin color range for hsv color space \n","#         HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n","#         HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n","\n","#         #converting from gbr to YCbCr color space\n","#         img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n","#         #skin color range for hsv color space \n","#         YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n","#         YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n","\n","#         #merge skin detection (YCbCr and hsv)\n","#         global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n","#         global_mask=cv2.medianBlur(global_mask,3)\n","#         global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))\n","\n","\n","#         HSV_result = cv2.bitwise_not(HSV_mask)\n","#         YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n","#         global_result=cv2.bitwise_not(global_mask)\n","\n","\n","#         #show results\n","#         # cv2.imshow(\"1_HSV.jpg\",HSV_result)\n","#         # cv2.imshow(\"2_YCbCr.jpg\",YCrCb_result)\n","#         # cv2.imshow(\"3_global_result.jpg\",global_result)\n","#         # cv2.imshow(\"Image.jpg\",img)\n","#         if cat==\"m0\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/HSV/m0/\"+str(i)+\"_\"+cat+\"_HSV.jpg\",HSV_result)\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/YCbCr/m0/\"+str(i)+\"_\"+cat+\"_YCbCr.jpg\",YCrCb_result)\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/HSV_YCbCr/m0/\"+str(i)+\"_\"+cat+\"_HSV_YCbCr.jpg\",global_result)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows()  \n","#         if cat==\"m1\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/HSV/m1/\"+str(i)+\"_\"+cat+\"_HSV.jpg\",HSV_result)\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/YCbCr/m1/\"+str(i)+\"_\"+cat+\"_YCbCr.jpg\",YCrCb_result)\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/HSV_YCbCr/m1/\"+str(i)+\"_\"+cat+\"_HSV_YCbCr.jpg\",global_result)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows() \n","#         if cat==\"m2\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/HSV/m2/\"+str(i)+\"_\"+cat+\"_HSV.jpg\",HSV_result)\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/YCbCr/m2/\"+str(i)+\"_\"+cat+\"_YCbCr.jpg\",YCrCb_result)\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/HSV_YCbCr/m2/\"+str(i)+\"_\"+cat+\"_HSV_YCbCr.jpg\",global_result)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows() \n","\n"],"metadata":{"id":"jLCBrjFoml2d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## hair line contour\n"],"metadata":{"id":"hPTq44G7s07c"}},{"cell_type":"code","source":["# import cv2\n","# import numpy as np\n","# from PIL import Image\n","# import os, glob, numpy as np\n","\n","# image = cv2.imread(\"/content/drive/MyDrive/hairloss_image/boundingbox/m0/1.PNG\", cv2.IMREAD_COLOR)\n","# image2 = image.copy()\n","# gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# return_value, threshold_image = cv2.threshold(gray_image,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","# contours, hierarchy = cv2.findContours(threshold_image, \n","#                         cv2.RETR_LIST, \n","#                         cv2.CHAIN_APPROX_NONE)\n","\n","# for contour in contours:\n","#     cv2.drawContours(image,contour,-1,(0,0,255),2)\n","    \n","# threshold_image = np.stack((threshold_image,)*3, axis=-1)\n","# image = np.concatenate((image,threshold_image), axis=1)\n","# image = np.concatenate((image,image2), axis=1)"],"metadata":{"id":"WllsmXKEs6qa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #line detect 전처리 이미지 파일 생성 코드\n","\n","# import cv2\n","# import numpy as np\n","# from PIL import Image\n","# import os, glob, numpy as np\n","# from sklearn.model_selection import train_test_split\n","\n","# caltech_dir = \"/content/drive/MyDrive/hairloss_image/boundingbox\"\n","# categories = [\"m0\", \"m1\", \"m2\",]\n","# nb_classes = len(categories)\n","\n","# for idx, cat in enumerate(categories):\n","    \n","#     #one-hot 돌리기.\n","#     label = [0 for i in range(nb_classes)]\n","#     label[idx] = 1\n","#     image_dir = caltech_dir + \"/\" + cat\n","#     files = glob.glob(image_dir+\"/*.PNG\") # 확장자 주의\n","#     #files = glob.glob(image_dir+\"/*.jpg\") # 확장자 주의\n","#     print(cat, \" 파일 길이 : \", len(files))\n","#     for i, f in enumerate(files):\n","\n","#         src = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n","\n","#         if src is None:\n","#             print('Image load failed!')\n","#             sys.exit()\n","\n","#         _, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n","\n","#         contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","\n","#         h, w = src.shape[:2]\n","#         dst = np.zeros((h, w, 3), np.uint8)\n","\n","#         for j in range(len(contours)):\n","#             #c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n","#             c = (0,0,255)\n","#             cv2.drawContours(dst, contours, j, c, 1, cv2.LINE_AA)\n","#         print(src_bin.shape)\n","#         #cv2_imshow(src)\n","#         #cv2_imshow(src_bin)\n","#         #cv2_imshow(dst)\n","#         #cv2.waitKey()\n","#         #cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/0.jpg\",dst)\n","#         #cv2.destroyAllWindows()\n","\n","#         #show results\n","#         # cv2.imshow(\"1_HSV.jpg\",HSV_result)\n","#         # cv2.imshow(\"2_YCbCr.jpg\",YCrCb_result)\n","#         # cv2.imshow(\"3_global_result.jpg\",global_result)\n","#         # cv2.imshow(\"Image.jpg\",img)\n","#         if cat==\"m0\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/contours_wb/m0/\"+str(i)+\"_\"+cat+\"_contours_wb.jpg\",src_bin)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows()  \n","#         if cat==\"m1\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/contours_wb/m1/\"+str(i)+\"_\"+cat+\"_contours_wb.jpg\",src_bin)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows() \n","#         if cat==\"m2\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/boundingbox/contours_wb/m2/\"+str(i)+\"_\"+cat+\"_contours_wb.jpg\",src_bin)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows() "],"metadata":{"id":"veKXLeYx1e_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import cv2\n","# from google.colab.patches import cv2_imshow\n","\n","# src = cv2.imread(\"/content/drive/MyDrive/hairloss_image/boundingbox/m0/1.PNG\", cv2.IMREAD_COLOR)\n","\n","# gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n","# ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n","# binary = cv2.bitwise_not(binary)\n","\n","# contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n","\n","# for i in range(len(contours)):\n","#     cv2.drawContours(src, [contours[i]], 0, (0, 0, 255), 2)\n","#     #cv2.putText(src, str(i), tuple(contours[i][0][0]), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1)\n","#     #print(i, hierarchy[0][i])\n","#     cv2.waitKey(0)\n","# cv2_imshow(src)\n","# cv2.destroyAllWindows()"],"metadata":{"id":"xq8La79ivcSD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import sys\n","# import random\n","# import numpy as np\n","# import cv2\n","# from google.colab.patches import cv2_imshow\n","\n","\n","# src = cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m2/1785020417_0b6Scamj_fcbe5dac215f6506fa142ee216a872b9860b5e2c.jpg\", cv2.IMREAD_GRAYSCALE)\n","\n","# if src is None:\n","#     print('Image load failed!')\n","#     sys.exit()\n","\n","# _, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n","\n","# contours, _ = cv2.findContours(src_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n","\n","# h, w = src.shape[:2]\n","# dst = np.zeros((h, w, 3), np.uint8)\n","\n","# for i in range(len(contours)):\n","#     #c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n","#     c = (0,0,255)\n","#     cv2.drawContours(dst, contours, i, c, 1, cv2.LINE_AA)\n","\n","# cv2_imshow(src)\n","# cv2_imshow(src_bin)\n","# cv2_imshow(dst)\n","# cv2.waitKey()\n","# #cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/0.jpg\",dst)\n","# cv2.destroyAllWindows()\n","# print(len(contours))\n"],"metadata":{"id":"JIcKbI8dzQkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import cv2 \n","# import matplotlib.pyplot as plt \n","# img = cv2.imread(\"/content/drive/MyDrive/hairloss_image/boundingbox/contours/m0/0_m0_contours.jpg\", cv2.IMREAD_GRAYSCALE) \n","# canny = cv2.Canny(img, 30, 70) \n","# sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3) \n","# sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3) \n","# laplacian = cv2.Laplacian(img, cv2.CV_8U) \n","\n","# images = [canny, sobelx, sobely, laplacian] \n","# titles = ['canny', 'sobelx', 'sobely', 'laplacian'] \n","\n","# for i in range(4): \n","# \tplt.subplot(2, 2, i+1), \n","# \tplt.imshow(images[i]), plt.title(titles[i]), plt.xticks([]), plt.yticks([]) \n","# plt.show()"],"metadata":{"id":"0Uyv1iDidcEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### auto boundingbox\n"],"metadata":{"id":"agp-VwaPaufS"}},{"cell_type":"code","source":["# #bounding box 전처리 이미지 파일 생성 코드\n","\n","# import cv2\n","# import numpy as np\n","# from PIL import Image\n","# import os, glob, numpy as np\n","# from sklearn.model_selection import train_test_split\n","# import sys\n","# from matplotlib import pyplot as plt\n","# from google.colab.patches import cv2_imshow\n","\n","# caltech_dir = \"/content/drive/MyDrive/hairloss_image/original\"\n","# categories = [\"m0\", \"m1\", \"m2\",]\n","# nb_classes = len(categories)\n","\n","# for idx, cat in enumerate(categories):\n","    \n","#     #one-hot 돌리기.\n","#     label = [0 for i in range(nb_classes)]\n","#     label[idx] = 1\n","#     image_dir = caltech_dir + \"/\" + cat\n","#     #files = glob.glob(image_dir+\"/*.PNG\") # 확장자 주의\n","#     files = glob.glob(image_dir+\"/*.jpg\") # 확장자 주의\n","\n","#     print(cat, \" 파일 길이 : \", len(files))\n","\n","#     for k, f in enumerate(files):\n","#         original_src=cv2.imread(f)\n","#         src = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n","\n","#         if src is None:\n","#             print('Image load failed!')\n","#             sys.exit()\n","\n","#         _, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n","\n","#         contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)   ## mode와 method에 따라 연산 시간 차이가 많이나니 주의\n","\n","#         h, w = src.shape[:2]\n","#         dst = np.zeros((h, w, 3), np.uint8)\n","\n","#         for j in range(len(contours)):         \n","#             c = (0,0,255)\n","#             cv2.drawContours(dst, contours, j, c, 1, cv2.LINE_AA)\n","        \n","#         edged = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n","\n","#         kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n","#         closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n","\n","#         contours, _ = cv2.findContours(closed.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","#         contours_xy = np.array(contours)\n","#         contours_xy.shape\n","\n","#         x_min, x_max = 0,0\n","#         value = list()\n","\n","#         ## 시간이 오래걸려서 최적화가 필요할듯\n","\n","#         for i in range(len(contours_xy)):\n","#             for j in range(len(contours_xy[i])):\n","#                 value.append(contours_xy[i][j][0][0]) #네번째 괄호가 0일때 x의 값\n","#                 x_min = min(value)\n","#                 x_max = max(value)\n","        \n","#         # y의 min과 max 찾기\n","#         y_min, y_max = 0,0\n","#         value = list()\n","#         for q in range(len(contours_xy)):\n","#             for w in range(len(contours_xy[q])):\n","#                 value.append(contours_xy[q][w][0][1]) #네번째 괄호가 0일때 x의 값\n","#                 y_min = min(value)\n","#                 y_max = max(value)\n","\n","#         x = x_min\n","#         y = y_min\n","#         w = x_max-x_min\n","#         h = y_max-y_min\n","\n","#         img_trim = original_src[y:y+h, x:x+w]\n","\n","#         if x==0 and y==0 and w==0 and h==0:  #에러발생 방지?? 이유는 아직 모름\n","#           continue    \n","    \n","#         if cat==\"m0\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/autoboundingbox/m0/\"+str(k)+\"_\"+cat+\"_auto_boundingbox.jpg\",img_trim)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows()  \n","#         if cat==\"m1\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/autoboundingbox/m1/\"+str(k)+\"_\"+cat+\"_auto_boundingbox.jpg\",img_trim)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows() \n","#         if cat==\"m2\":\n","#             cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/autoboundingbox/m2/\"+str(k)+\"_\"+cat+\"_auto_boundingbox.jpg\",img_trim)\n","#             cv2.waitKey(0)\n","#             cv2.destroyAllWindows() "],"metadata":{"id":"OGXt6wvnbHy2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import cv2, sys\n","# from matplotlib import pyplot as plt\n","# import numpy as np\n","# from google.colab.patches import cv2_imshow\n","\n","# original_image= cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m0/2943053909_yBCm9ScN_4c0ccd753966fabd0a1c029da8c7a053dfb1aae7.jpg\")\n","# image = cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m0/2943053909_yBCm9ScN_4c0ccd753966fabd0a1c029da8c7a053dfb1aae7.jpg\")\n","# image_gray = cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m0/2943053909_yBCm9ScN_4c0ccd753966fabd0a1c029da8c7a053dfb1aae7.jpg\", cv2.IMREAD_GRAYSCALE)\n","\n","# # b,g,r = cv2.split(image)\n","# # image2 = cv2.merge([r,g,b])\n"," \n","# # plt.imshow(image2)\n","# # plt.xticks([])\n","# # plt.yticks([])\n","# # plt.show()\n","\n","# src = cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m2/1785020417_0b6Scamj_fcbe5dac215f6506fa142ee216a872b9860b5e2c.jpg\", cv2.IMREAD_GRAYSCALE)\n","\n","# if src is None:\n","#     print('Image load failed!')\n","#     sys.exit()\n","\n","# _, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n","\n","# contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","# h, w = src.shape[:2]\n","# dst = np.zeros((h, w, 3), np.uint8)\n","\n","# for i in range(len(contours)):\n","#     #c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n","#     c = (0,0,255)\n","#     cv2.drawContours(dst, contours, i, c, 1, cv2.LINE_AA)\n","\n","# # cv2_imshow(src)\n","# # cv2_imshow(src_bin)\n","# # cv2_imshow(dst)\n","# # cv2.waitKey()\n","# # #cv2.imwrite(\"/content/drive/MyDrive/hairloss_image/0.jpg\",dst)\n","# # cv2.destroyAllWindows()\n","# # print(len(contours))\n","\n","# edged = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n","# closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n","\n","# contours, _ = cv2.findContours(closed.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","# #total = 0\n","\n","# #contours_image = cv2.drawContours(image, contours, -1, (0,255,0), 3)\n","\n","# contours_xy = np.array(contours)\n","# contours_xy.shape\n","\n","# x_min, x_max = 0,0\n","# value = list()\n","\n","# ## 시간이 오래걸려서 최소화가 필요할듯\n","\n","# for i in range(len(contours_xy)):\n","#     for j in range(len(contours_xy[i])):\n","#         value.append(contours_xy[i][j][0][0]) #네번째 괄호가 0일때 x의 값\n","#         x_min = min(value)\n","#         x_max = max(value)\n"," \n","# # y의 min과 max 찾기\n","# y_min, y_max = 0,0\n","# value = list()\n","# for i in range(len(contours_xy)):\n","#     for j in range(len(contours_xy[i])):\n","#         value.append(contours_xy[i][j][0][1]) #네번째 괄호가 0일때 x의 값\n","#         y_min = min(value)\n","#         y_max = max(value)\n","\n","# # image trim 하기\n","# x = x_min\n","# y = y_min\n","# w = x_max-x_min\n","# h = y_max-y_min\n","\n","# print(x,y,w,h)\n","      \n","# img_trim = original_image[y:y+h, x:x+w]\n","# #cv2.imwrite('org_trim.jpg', img_trim)\n","# #org_image = cv2.imread(img_trim)\n","\n","# cv2_imshow(img_trim)\n","# #cv2.imwrite('org_trim.jpg', img_trim)\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"],"metadata":{"id":"qGYkgDFolRNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cv2_imshow(image)\n","# cv2_imshow(image_gray)\n"," \n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"],"metadata":{"id":"yCNN4zX7lgmH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# blur = cv2.GaussianBlur(image_gray, ksize=(3,3), sigmaX=0)  #k size 조정필요\n","# ret, thresh1 = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY)\n","# #ret, thresh1 = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n"],"metadata":{"id":"StT5FJjvlsP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #edged = cv2.Canny(blur, 10, 250)\n","# edged = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY )\n","# cv2_imshow(edged)\n","# cv2.waitKey(0)\n","# print(edged.shape)"],"metadata":{"id":"2CwHh_FMl1mx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n","# closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n","# cv2_imshow(closed)\n","# cv2.waitKey(0)\n"],"metadata":{"id":"aUyqkZrqmBUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# contours, _ = cv2.findContours(closed.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","# total = 0\n","\n","# contours_image = cv2.drawContours(image, contours, -1, (0,255,0), 3)\n","# cv2_imshow(contours_image)\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"],"metadata":{"id":"YCxULqwQmKWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# contours_xy = np.array(contours)\n","# contours_xy.shape"],"metadata":{"id":"gigYU5AaA76U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# x_min, x_max = 0,0\n","# value = list()\n","# for i in range(len(contours_xy)):\n","#     for j in range(len(contours_xy[i])):\n","#         value.append(contours_xy[i][j][0][0]) #네번째 괄호가 0일때 x의 값\n","#         x_min = min(value)\n","#         x_max = max(value)\n","# print(x_min)\n","# print(x_max)\n"," \n","# # y의 min과 max 찾기\n","# y_min, y_max = 0,0\n","# value = list()\n","# for i in range(len(contours_xy)):\n","#     for j in range(len(contours_xy[i])):\n","#         value.append(contours_xy[i][j][0][1]) #네번째 괄호가 0일때 x의 값\n","#         y_min = min(value)\n","#         y_max = max(value)\n","# print(y_min)\n","# print(y_max)\n"],"metadata":{"id":"sWhlueQaA_Ip"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # image trim 하기\n","# x = x_min\n","# y = y_min\n","# w = x_max-x_min\n","# h = y_max-y_min\n"],"metadata":{"id":"a9FPqO7yBDPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# img_trim = [y:y+h, x:x+w]\n","# #cv2.imwrite('org_trim.jpg', img_trim)\n","# #org_image = cv2.imread(img_trim)"],"metadata":{"id":"klGVZ2uZBF2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cv2_imshow(img_trim)\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"],"metadata":{"id":"fkUGndfjBQ1x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## contours"],"metadata":{"id":"yZPibVlU0FMi"}},{"cell_type":"code","source":["# import numpy as np\n","# import cv2\n","# from google.colab.patches import cv2_imshow\n","# from matplotlib import pyplot as plt\n","\n","# img = cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m2/1785020417_0b6Scamj_fcbe5dac215f6506fa142ee216a872b9860b5e2c.jpg\")\n","# #imgray=cv2.imread(\"/content/drive/MyDrive/hairloss_image/original/m2/1785020417_0b6Scamj_fcbe5dac215f6506fa142ee216a872b9860b5e2c.jpg\", cv2.IMREAD_GRAYSCALE)\n","# imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","# print(imgray.shape)\n","\n","# rows, cols = img.shape[:2]\n","\n","# ret, thr = cv2.threshold(imgray, 127, 255, 0)\n","\n","# contours, _ = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","# print(len(contours))\n","# print(type(contours))\n","# #print(contours)\n","\n","# cnt = contours[5]\n","# print(type(cnt),len(cnt),cnt)\n","\n","\n","# (x , y), r = cv2.minEnclosingCircle(cnt)\n","# center = (int(x), int(y))\n","# r= int(r)\n","\n","# #cv2.circle(img, center, r, (255,0,0), 3)\n","# #ellipse = cv2.fitEllipse(cnt)\n","# #cv2.ellipse(img, ellipse, (0, 255, 0), 3)\n","# [vx, vy, x, y] = cv2.fitLine(cnt, cv2.DIST_L2, 0, 0.01, 0.01)\n","# ly = int((-x*vy/vx) + y)\n","# ry = int(((cols-x)*vy/vx) + y)\n","\n","\n","# cv2.line(img, (cols-1, ry), (0,ly), (0, 255, 255), 2)\n","\n","# cv2_imshow(img)\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()\n"],"metadata":{"id":"yRS7DkM4ZLDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # import cv2\n","# # from skimage.data import horse\n","\n","# # img_raw = horse().astype('uint8')\n","# # img_raw = np.ones(img_raw.shape) - img_raw\n","\n","# # img = img_raw.copy().astype('uint8')\n","\n","# contours, hierachy = cv2.findContours(imgray, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n","\n","# print(imgray.shape)"],"metadata":{"id":"gLTBfSYSb97D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# len(contours)"],"metadata":{"id":"eMfn870rcbKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# contours[0].shape"],"metadata":{"id":"KL3eXvHcccBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.squeeze(contours[0])[:5]"],"metadata":{"id":"JuDrz18acdqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# x0, y0 = zip(*np.squeeze(contours[0]))\n","# plt.plot(x0, y0, c=\"b\")\n","# plt.show()"],"metadata":{"id":"VxeypyD5ciNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hierachy"],"metadata":{"id":"blcUFvaQckKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# c0 = contours[0]\n","# M = cv2.moments(c0)\n","\n","# print(c0)"],"metadata":{"id":"agi0aM0scmz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # img1 = img_raw.copy().astype(\"uint8\")\n","# # img2 = img_raw.copy().astype(\"uint8\")\n","\n","# # Straight Rectangle\n","# x, y, w, h = cv2.boundingRect(c0)\n","# img1 = cv2.rectangle(imgray, (x, y), (x+w, y+h), 7)\n","\n","# # Rotated Rectangle\n","# rect = cv2.minAreaRect(c0)\n","# box = cv2.boxPoints(rect)\n","# box = box.astype('int')\n","# img2 = cv2.drawContours(imgray, [box], -1, 7) # blue\n","\n","# plt.subplot(1,2,1)\n","# plt.imshow(img1, cmap=\"brg\")\n","# plt.axis('off')\n","# plt.title(\"Straight Rectangle\")\n","# plt.subplot(1,2,2)\n","# plt.imshow(img2, cmap=\"brg\")\n","# plt.axis('off')\n","# plt.title(\"Rotated Rectangle\")\n","# plt.show()"],"metadata":{"id":"Qu13F4qoe_7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (x, y), radius = cv2.minEnclosingCircle(c0)\n","# center = int(x), int(y)\n","# radius = int(radius)\n","# img3 = cv2.circle(imgray, center, radius, 7)\n","\n","# ellipse = cv2.fitEllipse(c0)\n","# img4 = cv2.ellipse(imgray, ellipse, 7)\n","\n","\n","# plt.subplot(1,2,1)\n","# plt.imshow(img3, cmap=\"gray\")\n","# plt.axis('off')\n","# plt.title(\"Minumum Enclosing Circle\")\n","# plt.subplot(1,2,2)\n","# plt.imshow(img4, cmap=\"gray\")\n","# plt.axis('off')\n","# plt.title(\"Fitting Ellipse\")\n","# plt.show()"],"metadata":{"id":"q2ehKcDAb0mt"},"execution_count":null,"outputs":[]}]}